name: Main Check
run-name: ${{ github.actor }} made changes
on:
  pull_request:
    branches: [main]
  push:
    branches: [main]

jobs:
  detect-changes:
    runs-on: ubuntu-latest
    outputs:
      ui: ${{ steps.filter.outputs.ui }}
      server: ${{ steps.filter.outputs.server }}
      python_client: ${{ steps.filter.outputs.python_client }}
      func_tests: ${{ steps.filter.outputs.func_tests }}
      embedded_ml_sdk: ${{ steps.filter.outputs.embedded_ml_sdk }}
      black_formating: ${{ steps.filter.outputs.server == 'true' || steps.filter.outputs.python_client == 'true' || steps.filter.outputs.func_tests == 'true' }}
      server_unit_tests: ${{ steps.filter.outputs.server == 'true' || steps.filter.outputs.python_client == 'true' }}

    steps:
      - uses: actions/checkout@v4
      - name: Check diff
        id: filter
        uses: dorny/paths-filter@v3
        with:
          base: "main"
          filters: |
            ui:
              - 'src/ui/**'
            server:
              - 'src/server/**'
            python_client:
              - 'src/python_client/**'
            func_tests:
              - 'func_tests/**'
            embedded_ml_sdk:
              - 'src/embedded_ml_sdk/**'
  check-ui:
    name: UI Check Formatting / Run Unit tests running
    needs: detect-changes
    if: ${{ needs.detect-changes.outputs.ui == 'true' }}

    runs-on: ubuntu-latest
    container:
      image: node:16-alpine3.15

    steps:
      - uses: actions/checkout@v4
      - name: Install node packages
        run: yarn --cwd src/ui install
      - name: Run Eslint
        run: yarn --cwd src/ui eslint
      - name: Run Unit Tests
        run: yarn --cwd src/ui test:output
      - name: Upload UI tests report
        if: success()
        uses: actions/upload-artifact@v3
        with:
          name: junit-ui-report
          path: src/ui/ui-report-out.xml
      - name: Surface failing UI tests
        if: success()
        uses: pmeier/pytest-results-action@main
        with:
          path: src/ui/ui-report-out.xml
          summary: true
          display-options: fEX
          fail-on-empty: true
          title: UI unit test results

  check-black-formating:
    name: Check Formatting Black
    needs: detect-changes
    if: ${{ needs.detect-changes.outputs.black_formating == 'true' }}

    runs-on: ubuntu-latest
    container:
      image: sensiml/utest-server

    steps:
      - uses: actions/checkout@v4
      - name: Check Formatting Server
        if: ${{ needs.detect-changes.outputs.server == 'true' }}
        run: python -m black --check src/server/

      - name: Check Formatting Python Client
        if: ${{ needs.detect-changes.outputs.python_client == 'true' }}
        run: python -m black --check src/python_client

      - name: Check Formatting Function Test
        if: ${{ needs.detect-changes.outputs.func_tests == 'true' }}
        run: python -m black --check func_tests/

  run-server-unit-tests:
    name: "Run Server Unit Tests"
    needs:
      - detect-changes
    if: ${{ needs.detect-changes.outputs.server_unit_tests == 'true' }}

    runs-on: ubuntu-latest
    container:
      image: sensiml/utest-server
    services:
      db:
        image: postgres
        env:
          POSTGRES_DB: piccolodb
          POSTGRES_USER: piccoloadmin
          POSTGRES_PASSWORD: piccoloadmin3
        ports:
          - 5432:5432
      redis:
        image: redis
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          # Maps port 6379 on service container to the host
          - 6379:6379

    steps:
      - uses: actions/checkout@v4
        with:
          lfs: true
      - name: Get working directory
        run: |
          echo "WORKING_DIR=$(pwd)" >> $GITHUB_ENV
      - name: Run Unit Tests
        run: |
          export DJANGO_ENV=test
          export DJANGO_ENV_PATH=/${{ env.WORKING_DIR }}/src/server/config/env/
          export HOMEDIR=/${{ env.WORKING_DIR }}/src
          export CLASSIFIER_LIBS=/${{ env.WORKING_DIR }}/src/lib/
          # update requirements.txt in case new libraries were added
          pip install -r src/server/requirements.txt && python -c "from mltk.core.tflite_micro.accelerators.mvp.estimator.utils import download_estimators; download_estimators()"
          mkdir /${{ env.WORKING_DIR }}/src/lib
          /bin/bash src/embedded_ml_sdk/scripts/setup_classifiers.sh
          cd /${{ env.WORKING_DIR }}/src/embedded_ml_sdk/pywrapper
          make -j
          cd /${{ env.WORKING_DIR }}/src/server
          py.test --durations=0 --junitxml=/${{ env.WORKING_DIR }}/report_out.xml --html=unittest_report.html --cov=./ --cov-report html:cov_html library/tests/core_functions -n 4
      - name: Upload server unit tests report
        if: success()
        uses: actions/upload-artifact@v3
        with:
          name: junit-server-report
          path: /${{ env.WORKING_DIR }}/report_out.xml
      - name: Surface failing server tests
        if: success()
        uses: pmeier/pytest-results-action@main
        with:
          path: /${{ env.WORKING_DIR }}/report_out.xml
          summary: true
          display-options: fEX
          fail-on-empty: true
          title: Server unit test results

  run-embedded-ml-unit-tests:
    name: Run Embedded ML Unit Tests
    needs:
      - detect-changes
    if: ${{ needs.detect-changes.outputs.embedded_ml_sdk == 'true' }}
    runs-on: ubuntu-latest
    container:
      image: sensiml/embedded-ml-utest
    steps:
      - uses: actions/checkout@v4
      - name: Run unit tests
        run: |
          cd src/embedded_ml_sdk/utest
          bash build.sh
      - name: Upload embedded unit tests report
        if: success()
        uses: actions/upload-artifact@v3
        with:
          name: junit-server-report
          path: src/embedded_ml_sdk/utest/out/test_results.xml
      - name: Surface failing embeded tests
        if: success()
        uses: pmeier/pytest-results-action@main
        with:
          path: src/embedded_ml_sdk/utest/out/test_results.xml
          summary: true
          display-options: fEX
          fail-on-empty: true
          title: Embedded ML Unit Test results
